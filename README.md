# Digital_Pathology-NN-
(KrivohizhinDN)

Цель - реализовать модель для классификации фрагментов полнокадровых гистологических
изображений (патчей) на 9 классов: [ADI, BACK, DEB, LYM, MUC, MUS, NORM, STR, TUM]. Каждый патч представляет собой цветное (8-bit) изображение 224 × 224 px. 

Подход - использование предобученной на IMAGENET1k модели - EfficientNet_B3_Weights.IMAGENET1K_V1

Почему именно она? - По статистике с Бенчмарка моделей(https://paperswithcode.com/sota/image-classification-on-imagenet) efficientnet в целом лучше чем resnet(если говорить про похожие по качество\ресурсозатратность) модели:
EfficientNet_B3_Weights.IMAGENET1K_V1:  | ResNet18_Weights.IMAGENET1K_V1:
acc@1 (on ImageNet-1K)                  | acc@1 (on ImageNet-1K)
82.008                                  | 69.758
acc@5 (on ImageNet-1K)                  | acc@5 (on ImageNet-1K)
96.054                                  | 89.078



Дообучение происходило в 20 эпох(больше ~= переобучение) на train.npz датасете, с применением аугментаций до 12 эпохи(открыл для себя такой механизм - частичной аугментации). 

По итогу, после 20 эпох, модель обладала следующими показателями:
Training Loss: 0.0094
Validation Loss: 0.0271, Accuracy: 0.9920
Что, как мне кажется, является очень хорошим результатом.

Дополнительно, в рамках стратегии по заработку доп. баллов за это задание, а также веселья ради, было реализованно:


#LBL1.Валидация модели на части обучающей выборки:  
Реализована. Данные разделены на обучающие и валидационные наборы с помощью функции `train_test_split`. В процессе обучения модель валидируется на валидационной выборке, что позволяет контролировать переобучение и оценивать её обобщающую способность.

#LBL2.Автоматическая кросс-валидация:  
Реализована. Использован `KFold` из `sklearn.model_selection` для проведения K-фолд кросс-валидации. Это позволяет оценить модель на разных подмножествах данных и получить более надёжные метрики производительности.

#LBL3.Автоматическое сохранение модели при обучении:  
Реализовано. Модель автоматически сохраняется после каждой эпохи обучения. Также сохраняется лучшая модель на основе минимальной валидационной потери, что гарантирует сохранение оптимальных весов.

#LBL4.Загрузка модели с какой-то конкретной итерации обучения (если используется итеративное обучение):  
Реализована возможность загружать модель из конкретного чекпоинта. Это позволяет продолжить обучение с определённой эпохи или использовать сохранённую модель для инференса.

#LBL5.Вывод различных показателей в процессе обучения (например, значение функции потерь на каждой эпохе):  
Реализовано. В процессе обучения выводятся и логируются метрики, такие как функция потерь (loss) и точность (accuracy) на обучающем и валидационном наборах после каждой эпохи.

#LBL6.Построение графиков, визуализирующих процесс обучения (график зависимости функции потерь от номера эпохи обучения, и т.п.):  
Реализовано. С помощью Weights & Biases (WandB) автоматически визуализируется процесс обучения. Логируются графики функции потерь и точности по эпохам, что позволяет отслеживать динамику обучения в режиме реального времени.

#LBL7.Автоматическое тестирование на тестовом наборе/наборах данных после каждой эпохи обучения (при использовании итеративного обучения):  
Частично реализовано. Выполняется оценка модели на валидационном наборе после каждой эпохи. Тестирование на отдельном тестовом наборе (test_tiny.npz) выполняется после завершения обучения, а не после каждой эпохи.

#LBL8.Построение матрицы ошибок, оценивание чувствительности и специфичности модели:  
Реализовано. Добавлены функции для вычисления и вывода матрицы ошибок (confusion matrix), а также метрик чувствительности (sensitivity) и специфичности (specificity) для каждого класса. Это помогает детально анализировать работу модели на разных классах.

#LBL9.Автоматическое сохранение и визуализация результатов тестирования:  
Реализовано. Результаты тестирования сохраняются в файл (.npz), а также визуализируются. Сохраняются графики, такие как распределение предсказаний и матрицы ошибок, и логируются в WandB.

#LBL10.Использование аугментации и других способов синтетического расширения набора данных (дополнительным плюсом будет обоснование необходимости и обоснование выбора конкретных типов аугментации):  
Реализовано. Применены аугментации данных в виде случайного горизонтального и вертикального отражения, а также случайных поворотов на поздних этапах обучения. Это улучшает устойчивость модели к вариациям в данных и её обобщающую способность.

#LBL11.Реализация возможности дообучения модели (на новом наборе данных, или, например, при экстренном закрытии Google Colab):  
Реализована. Благодаря сохранению чекпоинтов и возможности их загрузки, обучение модели можно продолжить с последней сохранённой эпохи. Это полезно при непредвиденных остановках или необходимости дообучить модель на новых данных.

#LBL12.Любое дополнительное улучшение не из списка, улучшающее результаты классификации или улучшающее опыт взаимодействия с моделью:  
Интеграция с WandB для мониторинга и управления экспериментами: позволяет удобно отслеживать метрики, сравнивать различные запуски и визуализировать процесс обучения.  






Ссылки на рабочие директории(вдруг нужны):

"""Рабочая директория"""
https://drive.google.com/drive/folders/1naH9SgmepMqtFE1GXmiXk3dIHPWlkaWL?usp=sharing


"""Чекпоинты и веса лучшей модели"""
https://drive.google.com/drive/folders/10uLIj8PoVk1zWlG5kbgaTEnm7q23x7Fq?usp=sharing

(KrivohizhinDN)
